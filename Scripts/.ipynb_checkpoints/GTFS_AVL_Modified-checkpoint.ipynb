{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe764131",
   "metadata": {},
   "source": [
    "# GTFS and AVL Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "# Set the workspace environment to master folder\n",
    "x=os.chdir('C:\\\\Users\\\\Cole\\\\Desktop\\\\Spring2022\\\\AVLResearch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93695f",
   "metadata": {},
   "source": [
    "## GTFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a5108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the outputs from GTFS Joining(PANDAS)\n",
    "calendar = pd.read_csv('Data\\\\GTFS_Query\\\\cal_select.txt', index_col = False)\n",
    "routes = pd.read_csv('Data\\\\GTFS_Query\\\\routes_select.txt', index_col = False)\n",
    "shapes = pd.read_csv('Data\\\\GTFS_Query\\\\shapes_select.txt', index_col = False)\n",
    "stop_times= pd.read_csv('Data\\\\GTFS_Query\\\\stop_times_select.txt', index_col = False)\n",
    "stops = pd.read_csv('Data\\\\GTFS_Query\\\\stops_select.txt', index_col = False)\n",
    "trips = pd.read_csv('Data\\\\GTFS_Query\\\\trips_select.txt', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#should give you stop times w/ stop locations for each trip\n",
    "add_trip_stop_times = pd.merge(stop_times,trips,how = 'left', on = ['trip_id','route_id','service_id', 'trip_headsign','shape_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0518156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#error happens here? Fixed: left to outer join\n",
    "add_trip_stops = pd.merge(add_trip_stop_times,stops, how = 'outer', on = ['stop_id'])\n",
    "#add_trip_stops.to_csv(r\"C:\\Users\\Cole\\Desktop\\Spring2022\\AVLResearch\\Data\\ProcessedAVL_GTFS\\Test.csv\", index = False)\n",
    "\n",
    "add_trip_stops = add_trip_stops.sort_values(by =['trip_id', 'stop_sequence_x'])\n",
    "add_trip_stops.to_csv(r\"C:\\Users\\Cole\\Desktop\\Spring2022\\AVLResearch\\Data\\ProcessedAVL_GTFS\\Test.csv\", index = False)\n",
    "add_trip_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_trip_stops['SERV_DAY'] = add_trip_stops['trip_id'].str[22:-3]\n",
    "for index in range(len(add_trip_stops)):\n",
    "    if 'Northbound' in add_trip_stops.loc[index,'trip_headsign']:\n",
    "        add_trip_stops.loc[index,'dir_sign'] = 4\n",
    "    if 'Southbound' in add_trip_stops.loc[index,'trip_headsign']:\n",
    "        add_trip_stops.loc[index,'dir_sign'] = 1\n",
    "GTFSSum = add_trip_stops.replace({np.nan: None})\n",
    "#GTFSSum.to_csv(r\"C:\\Users\\Cole\\Desktop\\Spring2022\\AVLResearch\\Data\\ProcessedAVL_GTFS\\Test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b749914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedtrips = GTFSSum.groupby(\"trip_id\",sort=True)\n",
    "for group in groupedtrips:\n",
    "a = groupedtrips.head(1)\n",
    "b = groupedtrips.tail(1)\n",
    "#a.to_csv(r\"C:\\Users\\Cole\\Desktop\\Spring2022\\AVLResearch\\Data\\ProcessedAVL_GTFS\\Test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de7f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(a,b, on= 'trip_id',suffixes = ('_start','_end'))\n",
    "sumtableGTFS = final[['trip_id',\n",
    "                     'service_id_start',\n",
    "                     'trip_headsign_start',\n",
    "                      'dir_sign_start',\n",
    "                      'SERV_DAY_start',\n",
    "                     \n",
    "                     'stop_lat_start',\n",
    "                      'stop_lon_start',\n",
    "                      'arrival_time_start',\n",
    "                      'departure_time_start',\n",
    "                     'stop_id_start',\n",
    "                     'stop_name_start',\n",
    "                     'stop_desc_start',\n",
    "                     \n",
    "                      'stop_lat_end',\n",
    "                      'stop_lon_end',\n",
    "                      'arrival_time_end',\n",
    "                      'departure_time_end',\n",
    "                     'stop_id_end',\n",
    "                     'stop_name_end',\n",
    "                     'stop_desc_end'\n",
    "                     ]]\n",
    "sumtableGTFS = sumtableGTFS.sort_values('service_id', 'dir_sign_start','arrival_time_start')\n",
    "sumtableGTFS.to_csv(r\"C:\\Users\\Cole\\Desktop\\Spring2022\\AVLResearch\\Data\\ProcessedAVL_GTFS\\sumtableGTFS.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a27b48",
   "metadata": {},
   "source": [
    "## AVL (Give all AVL rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae1598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, tzinfo\n",
    "from dateutil import tz\n",
    "import pytz\n",
    "dataPath = \"C:\\\\Users\\Cole\\Desktop\\Spring2022\\AVLResearch\\Data\\Aline-vehicle-messages-Oct1_Oct8_2016\\Aline-vehicle-messages-Oct1_Oct8-2016.csv\"\n",
    "dataFrame = pd.read_csv(dataPath)\n",
    "avl_messages = dataFrame[[\"CALENDAR_ID\",\n",
    "                          \"MESSAGE_TIMESTAMP\",\n",
    "                          \"SOURCE_HOST\",\n",
    "                          \"ROUTE_ABBR\",\n",
    "                          \"DIRECTION\",\n",
    "                          \"LONGITUDE\",\n",
    "                          \"LATITUDE\",\n",
    "                         'SERVICE_ABBR']]\n",
    "avl_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6705d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(avl_messages)):\n",
    "    dt_str = avl_messages.loc[index, 'MESSAGE_TIMESTAMP']\n",
    "    dt_str1 = dt_str.replace('T',\" \").replace('Z',\"\")\n",
    "    try:\n",
    "        dt_utc = datetime.strptime(dt_str1,\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    except ValueError:\n",
    "        dt_utc = datetime.strptime(dt_str1,\"%Y-%m-%d %H:%M:%S\")\n",
    "    dt_utc2 = dt_utc.replace(tzinfo=pytz.UTC)\n",
    "    local_zone = tz.tzlocal()\n",
    "    dt_local = dt_utc2.astimezone(local_zone)\n",
    "    local_time_str = dt_local.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    avl_messages.loc[index,'TIME'] = local_time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca35f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sorted = avl_messages.sort_values([\"SOURCE_HOST\",\n",
    "                                        \"CALENDAR_ID\",\n",
    "                                        \"TIME\"],\n",
    "                                       axis=0,\n",
    "                                       ascending=(True, True,True))\n",
    "time_sorted.reset_index(inplace = True, drop = True)\n",
    "time_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d8a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "newframe = time_sorted.replace({np.nan: None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#may not need this at all\n",
    "newframe[\"TRIPSEQ\"] = \"\"\n",
    "tripcount = 0\n",
    "for index in range(len(newframe)):\n",
    "    if index == 0: \n",
    "        continue\n",
    "    else: \n",
    "        if newframe.loc[index,'CALENDAR_ID'] != newframe.loc[(index-1), 'CALENDAR_ID']:\n",
    "            tripcount = 0\n",
    "        else:\n",
    "            if newframe.loc[index,'SOURCE_HOST'] != newframe.loc[(index-1), 'SOURCE_HOST']:\n",
    "                tripcount = 0\n",
    "                newframe.at[index, 'TRIPSEQ'] = tripcount\n",
    "            else: #but if bus is the same...\n",
    "                if newframe.loc[index,'DIRECTION'] != newframe.loc[(index-1), 'DIRECTION']:\n",
    "                    tripcount = tripcount+1\n",
    "                    newframe.at[index, 'TRIPSEQ'] = tripcount\n",
    "                else:\n",
    "                    newframe.at[index, 'TRIPSEQ'] = newframe.loc[(index-1), 'TRIPSEQ']                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950af4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#may not need this at all\n",
    "newframe[\"TRIPSEQ\"] = \"\"\n",
    "tripcount = 0\n",
    "for index in range(len(newframe)):\n",
    "    if index == 0: \n",
    "        continue\n",
    "    else: \n",
    "        if newframe.loc[index,'CALENDAR_ID'] != newframe.loc[(index-1), 'CALENDAR_ID']:\n",
    "            tripcount = 0\n",
    "        else:\n",
    "            if newframe.loc[index,'SOURCE_HOST'] != newframe.loc[(index-1), 'SOURCE_HOST']:\n",
    "                tripcount = 0\n",
    "                newframe.at[index, 'TRIPSEQ'] = tripcount\n",
    "            else: #but if bus is the same...\n",
    "                if newframe.loc[index,'DIRECTION'] != newframe.loc[(index-1), 'DIRECTION']:\n",
    "                    tripcount = tripcount+1\n",
    "                    newframe.at[index, 'TRIPSEQ'] = tripcount\n",
    "                else:\n",
    "                    newframe.at[index, 'TRIPSEQ'] = newframe.loc[(index-1), 'TRIPSEQ'] \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc1529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#again, maybe not needed\n",
    "newframe[\"ID\"] = newframe[\"CALENDAR_ID\"].astype(\"str\") +\"-\"+ newframe[\"SOURCE_HOST\"].astype(\"str\") +\"-\"+ newframe[\"TRIPSEQ\"].astype(\"str\").str.zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f95fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "newframe = newframe.sort_values([\"CALENDAR_ID\",\"SERVICE_ABBR\",\"TIME\"],\n",
    "                                       axis=0,\n",
    "                                       ascending=(True, True,True))\n",
    "\n",
    "newframe[13760:13800]#.to_csv(r\"C:\\Users\\Cole\\Desktop\\Spring2022\\AVLResearch\\Data\\ProcessedAVL_GTFS\\test.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf0e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = newframe.groupby([\"ID\"])\n",
    "a = grouped.head(1)\n",
    "b = grouped.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b096051",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = newframe.groupby('ID').size().to_frame('size').reset_index()\n",
    "final1 = pd.merge(a,b,on=['CALENDAR_ID','SOURCE_HOST','TRIPSEQ'], suffixes = ('_start', '_end'))\n",
    "final1.to_csv(r\"C:\\Users\\Cole\\Desktop\\Spring2022\\AVLResearch\\Data\\ProcessedAVL_GTFS\\test.csv\", index = False)\n",
    "#gives start and end of each trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958091bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final2 = pd.merge(final1, counts, left_on= 'ID_start', right_on = 'ID')\n",
    "final2.to_csv(r\"C:\\Users\\Cole\\Desktop\\Spring2022\\AVLResearch\\Data\\ProcessedAVL_GTFS\\test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final3 = final2[[\"ID\",\n",
    "                 'CALENDAR_ID', \n",
    "                 \n",
    "               \"TIME_start\",\n",
    "               \"LONGITUDE_start\",\n",
    "               \"LATITUDE_start\",\n",
    "                 \n",
    "               \"TIME_end\",\n",
    "               \"LONGITUDE_end\",\n",
    "               \"LATITUDE_end\",\n",
    "                 \n",
    "                'ROUTE_ABBR_start',\n",
    "               \"DIRECTION_start\",\n",
    "                 \"SERV_DAY_start\",\n",
    "                 \"SERV_DAY_end\",\n",
    "                \"size\"\n",
    "                ]] \n",
    "\n",
    "final3 = final3.rename(columns = {'ROUTE_ABBR_start':'ROUTE_ABBR',\n",
    "                                  'DIRECTION_start': 'DIRECTION',\n",
    "                                 'size' : 'MESSAGE_COUNT',\n",
    "                                 'TIME_start': 'Literal_Time_start',\n",
    "                                 'TIME_end': 'Literal_Time_end'})\n",
    "final3 = final3.sort_values[]\n",
    "\n",
    "final3.to_csv(r\"C:\\Users\\Cole\\Desktop\\Spring2022\\AVLResearch\\Data\\ProcessedAVL_GTFS\\sumtableAVL.csv\",  index=False)               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6991c3",
   "metadata": {},
   "source": [
    "## AVL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c079aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, tzinfo\n",
    "from dateutil import tz\n",
    "import pytz\n",
    "dataPath = \"C:\\\\Users\\Cole\\Desktop\\Spring2022\\AVLResearch\\Data\\Aline-vehicle-messages-Oct1_Oct8_2016\\Aline-vehicle-messages-Oct1_Oct8-2016.csv\"\n",
    "dataFrame = pd.read_csv(dataPath)\n",
    "avl_messages = dataFrame[[\"CALENDAR_ID\",\n",
    "                          \"MESSAGE_TIMESTAMP\",\n",
    "                          \"LOCAL_TIMESTAMP\",\n",
    "                          \"SOURCE_HOST\",\n",
    "                          \"ROUTE_ABBR\",\n",
    "                          \"DIRECTION\",\n",
    "                          \"LONGITUDE\",\n",
    "                          \"LATITUDE\"]]\n",
    "newframe = avl_messages.replace({np.nan: None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "422413ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix local_time for each row in AVL full data \n",
    "for index in range(len(newframe)):\n",
    "    try:\n",
    "        dt_str = newframe.loc[index, 'LOCAL_TIMESTAMP']\n",
    "        dt_str1 = dt_str.replace('T',\"\").replace('Z',\"\")\n",
    "        t3 = datetime.strptime(dt_str1,\"%Y-%m-%d%H:%M:%S.%f\")\n",
    "    except:\n",
    "        pass\n",
    "    newframe.loc[index,'TIME'] = t3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca11960d",
   "metadata": {},
   "source": [
    "Local timestamp is not as specific as message timestamp;\n",
    "several messages in a row are given the same time.\n",
    "But say we remove any duplicates,\n",
    "so there is just one of each local timestamp time for simplicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a37c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#will eventually drop this cell\n",
    "#works for both versions\n",
    "newframe = newframe.drop_duplicates(subset = ['TIME'], keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ee18afa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cole\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Dropping invalid columns in DataFrameGroupBy.transform is deprecated. In a future version, a TypeError will be raised. Before calling .transform, select only columns which should be valid for the transforming function.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#sorts by bus # and then stripped LOCAL_TIME or ('TIME')\n",
    "time_sorted = newframe.sort_values([\"SOURCE_HOST\",\n",
    "                                        'TIME'],\n",
    "                                       axis=0,\n",
    "                                       ascending=(True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f3655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by source host (keeps them in time order) and reset index\n",
    "groupedhost = time_sorted.groupby('SOURCE_HOST')\n",
    "time_sorted.reset_index(drop=True)\n",
    "\n",
    "#Mark rows where the day ends and new day begins\n",
    "time_sorted['PREVDAY'] = groupedhost.transform(lambda x: x.shift(-1) > x+pd.Timedelta('1h'))\n",
    "time_sorted['NEXTDAY'] = time_sorted['PREVDAY'].shift(1)\n",
    "time_sorted.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c64bd3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select rows with marks, put them together, final sort, export\n",
    "final = time_sorted.loc[time_sorted['PREVDAY'] == True] \n",
    "final2 = time_sorted.loc[time_sorted['NEXTDAY'] == True]\n",
    "x = pd.concat([final,final2])\n",
    "y = x.sort_values([\"SOURCE_HOST\",'TIME'],axis=0,ascending=(True, True))\n",
    "y.to_csv(r\"C:\\Users\\Cole\\Desktop\\Spring2022\\AVLResearch\\Data\\ProcessedAVL_GTFS\\AVL_StartEnd.csv\",  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed7c33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
